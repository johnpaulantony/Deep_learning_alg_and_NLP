{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HZMh3H6XoEwA"
      },
      "outputs": [],
      "source": [
        "# import required lib\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense,Dropout\n",
        "from tensorflow.keras.datasets import imdb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load dataset\n",
        "vocab_size = 10000\n",
        "max_len=200\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNgv1C0kqh9V",
        "outputId": "4b872c25-f955-4689-b06c-bdb38703eb34"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VJEvoAdq2xT",
        "outputId": "6e2d0dbb-4d42-4736-e5bf-acd1314ac685"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pad sequences\n",
        "X_train=pad_sequences(x_train,maxlen=max_len,padding=\"post\")\n",
        "X_test=pad_sequences(x_test,maxlen=max_len,padding=\"post\")"
      ],
      "metadata": {
        "id": "mN_LKm5prIBn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSp29GvVrf2T",
        "outputId": "47f24985-ceb3-40cb-b911-b77ba84e1afc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[   5   25  100   43  838  112   50  670    2    9   35  480  284    5\n",
            "  150    4  172  112  167    2  336  385   39    4  172 4536 1111   17\n",
            "  546   38   13  447    4  192   50   16    6  147 2025   19   14   22\n",
            "    4 1920 4613  469    4   22   71   87   12   16   43  530   38   76\n",
            "   15   13 1247    4   22   17  515   17   12   16  626   18    2    5\n",
            "   62  386   12    8  316    8  106    5    4 2223 5244   16  480   66\n",
            " 3785   33    4  130   12   16   38  619    5   25  124   51   36  135\n",
            "   48   25 1415   33    6   22   12  215   28   77   52    5   14  407\n",
            "   16   82    2    8    4  107  117 5952   15  256    4    2    7 3766\n",
            "    5  723   36   71   43  530  476   26  400  317   46    7    4    2\n",
            " 1029   13  104   88    4  381   15  297   98   32 2071   56   26  141\n",
            "    6  194 7486   18    4  226   22   21  134  476   26  480    5  144\n",
            "   30 5535   18   51   36   28  224   92   25  104    4  226   65   16\n",
            "   38 1334   88   12   16  283    5   16 4472  113  103   32   15   16\n",
            " 5345   19  178   32]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the LSTM model\n",
        "model=Sequential([\n",
        "    Embedding(vocab_size,128,input_length=max_len),\n",
        "    LSTM(64,dropout=0.2,recurrent_dropout=0.2),\n",
        "    Dense(1,activation=\"sigmoid\"),\n",
        "\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U08k9toQr1XD",
        "outputId": "35d09e39-ff8a-4f5b-e3c4-7535acef1582"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile and Train the model\n",
        "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
        "model.fit(X_train,y_train,batch_size=64,epochs=3,validation_data=(X_test,y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woB5OmzStHIg",
        "outputId": "c7e50af6-2790-4036-c3d7-65725ae63df2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 717ms/step - accuracy: 0.5439 - loss: 0.6784 - val_accuracy: 0.6384 - val_loss: 0.6138\n",
            "Epoch 2/3\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 714ms/step - accuracy: 0.7230 - loss: 0.5568 - val_accuracy: 0.8267 - val_loss: 0.4371\n",
            "Epoch 3/3\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 830ms/step - accuracy: 0.8051 - loss: 0.4559 - val_accuracy: 0.6783 - val_loss: 0.5787\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x787aa26768d0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ✅ **Save the model (HDF5 format)**\n",
        "model.save(\"imdb_lstm_model.h5\")  # Saves in HDF5 format\n",
        "print(\"Model saved successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkYM4zDZwbKN",
        "outputId": "57c09620-4cd5-4ab4-90f9-298d05c60a78"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate and predict\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qsl9XhZEturU",
        "outputId": "0e950885-45b0-4899-a26a-08fd807e46c2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 111ms/step - accuracy: 0.6782 - loss: 0.5804\n",
            "Test Loss: 0.5787, Test Accuracy: 0.6783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.datasets import imdb\n",
        "\n",
        "# Load the IMDB word index (word to integer mapping)\n",
        "word_index = imdb.get_word_index()\n",
        "\n",
        "# Load the trained LSTM model (if saved earlier)\n",
        "model = tf.keras.models.load_model(\"imdb_lstm_model.h5\")\n",
        "\n",
        "# Function to preprocess a custom review\n",
        "def preprocess_review(review, vocab_size=10000, max_len=200):\n",
        "    words = review.lower().split()  # Convert to lowercase and split words\n",
        "    sequence = [word_index.get(word, 2) for word in words]  # Convert words to index (default 2 for <UNK>)\n",
        "    padded_sequence = pad_sequences([sequence], maxlen=max_len, padding=\"post\")  # Pad sequence\n",
        "    return padded_sequence\n",
        "\n",
        "# Function to predict sentiment\n",
        "def predict_sentiment(review):\n",
        "    processed_review = preprocess_review(review)\n",
        "    prediction = model.predict(processed_review)[0][0]  # Get the predicted probability\n",
        "    sentiment = \"Negative\" if prediction >= 0.5 else \"Positive\"\n",
        "\n",
        "    print(f\"Review: {review}\")\n",
        "    print(f\"Predicted Sentiment: {sentiment} (Confidence: {prediction:.4f})\\n\")\n",
        "\n",
        "# Test the model with custom movie reviews\n",
        "reviews = [\n",
        "    \"This movie was absolutely amazing! The acting was superb and the story was captivating.\",\n",
        "    \"I did not like the movie at all. It was boring and had a terrible storyline.\",\n",
        "    \"An average film. Some parts were good, but overall it felt slow.\",\n",
        "    \"One of the worst movies I have ever seen. Total waste of time!\"\n",
        "]\n",
        "\n",
        "for review in reviews:\n",
        "    predict_sentiment(review)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALHA1frMyPjZ",
        "outputId": "c8b2e9d9-e2d4-4c0d-caa2-59e4a144288f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step\n",
            "Review: This movie was absolutely amazing! The acting was superb and the story was captivating.\n",
            "Predicted Sentiment: Positive (Confidence: 0.0702)\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step\n",
            "Review: I did not like the movie at all. It was boring and had a terrible storyline.\n",
            "Predicted Sentiment: Negative (Confidence: 0.7560)\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step\n",
            "Review: An average film. Some parts were good, but overall it felt slow.\n",
            "Predicted Sentiment: Negative (Confidence: 0.8021)\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step\n",
            "Review: One of the worst movies I have ever seen. Total waste of time!\n",
            "Predicted Sentiment: Negative (Confidence: 0.6472)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}